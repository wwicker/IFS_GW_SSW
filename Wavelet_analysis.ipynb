{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6991d84-3faf-484e-b13b-8b99b904a88c",
   "metadata": {},
   "source": [
    "# Wavelet analysis\n",
    "\n",
    "Create Figure 7. This requires standard pressure level output of temperture to normalize potential temperature perturbations. These are derived from horizontally filterd model level ouput. The natural logarithm of model level surface pressure is required for the interpolation of model level output to fine pressure levels. Vertical wavelet power spectra to create Figure 7 are stored in this repository since their computation is expensive. Torrence & Campo (1998) and https://github.com/regeirk/pycwt are excellent references for wavelet analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5bd5f2-8b6e-46ee-95fa-378ea7d5b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import numba\n",
    "import dask.array\n",
    "from scipy.signal import tukey\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import cmocean\n",
    "import os\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78006101-cc2c-42b1-a57d-b0ed9c38996d",
   "metadata": {},
   "source": [
    "## Wavelet transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a805571-9ce9-4bf2-8df3-c4de0cda2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(da,dim):\n",
    "    '''\n",
    "        Zero padding to achieve length of an exponential of 2\n",
    "    '''\n",
    "    n = int(2 ** np.ceil(np.log2(len(da[dim])+1)))\n",
    "\n",
    "    pad = da.pad(pad_width={dim:(0,n-len(da[dim]))},\n",
    "                 mode='constant',\n",
    "                 constant_values=0)\n",
    "    \n",
    "    pad = pad.chunk({dim:-1})\n",
    "    \n",
    "    return pad\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def fft(da,dim,coord):\n",
    "    '''\n",
    "        Wrapper to use discrete Fourier transform with xarray.DataArray\n",
    "    '''\n",
    "    k = xr.DataArray(np.fft.fftfreq(len(coord),d=1/len(coord)),dims=('wavenumber_index'))\n",
    "    \n",
    "    # function that accepts dummy argument\n",
    "    fft = lambda da,k: dask.array.fft.fft(da) / len(k)\n",
    "    \n",
    "    transform = xr.apply_ufunc(fft,\n",
    "                               da,k,\n",
    "                               input_core_dims=[[dim],['wavenumber_index']],\n",
    "                               output_core_dims=[['wavenumber_index'],],\n",
    "                               dask='allowed',\n",
    "                               output_dtypes=[np.complex_]\n",
    "                              )\n",
    "    transform['wavenumber_index'] = k\n",
    "    \n",
    "    return transform\n",
    "\n",
    "\n",
    "\n",
    "def ifft(transform,dim,coord):\n",
    "    '''\n",
    "        Wrapper to use inverse discrete Fourier transform with xarray.DataArray\n",
    "    '''\n",
    "    # function that accepts dummy argument\n",
    "    irfft = lambda da,coord: dask.array.fft.ifft(da) * len(coord)\n",
    "    \n",
    "    da = xr.apply_ufunc(irfft,\n",
    "                        transform,coord,\n",
    "                        input_core_dims=[['wavenumber_index'],[dim]],\n",
    "                        output_core_dims=[[dim],],\n",
    "                        dask='allowed',\n",
    "                        output_dtypes=[np.float_]\n",
    "                        )\n",
    "    \n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839f443c-a9f4-4511-843b-31728333a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_wrapper(N,dz,dj=1/12):\n",
    "    '''\n",
    "        Wrapper for continous wavelet transform as described by Torrence & Compo (1998)\n",
    "    '''\n",
    "    \n",
    "    # Morlet window\n",
    "    flambda = (4 * np.pi) / (6 + np.sqrt(2 + 6 ** 2))\n",
    "    coi = 1. / np.sqrt(2)\n",
    "    psi_ft = lambda f: (np.pi ** -0.25) * np.exp(-0.5 * (f - 6) ** 2)\n",
    "    \n",
    "    s0 = 2 * dz / flambda\n",
    "    J = int(np.round(np.log2(N * dz / s0) / dj))\n",
    "    sj = xr.DataArray(s0 * 2 ** (np.arange(0, J + 1) * dj),dims=('scale',))\n",
    "    \n",
    "    # Fourier equivalent frequencies\n",
    "    wavelength = flambda * sj\n",
    "    # cone of influence where power of wavelet drops by exp(-2)\n",
    "    coi = sj / coi / flambda\n",
    "\n",
    "    wavenum = xr.DataArray(2 * np.pi * np.fft.fftfreq(N,d=dz),\n",
    "                           dims=('wavenumber_index'),\n",
    "                           coords=[np.fft.fftfreq(N,d=1/N)])\n",
    "    \n",
    "    # scaled wavelet transform\n",
    "    psi_ft_bar = (np.sqrt(sj * wavenum * N,dtype=complex) *\n",
    "                  np.conjugate(psi_ft(sj * wavenum)))\n",
    "    \n",
    "    return psi_ft_bar, wavelength, coi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abedde-b4f1-4fd4-a35d-2c23100641d4",
   "metadata": {},
   "source": [
    "## Interpolation to regular log-pressure grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae0913-72b4-4c11-b909-f6330b06faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale height\n",
    "H = 7000\n",
    "# reference pressure in hPa\n",
    "ps = 1013.25\n",
    "kappa = 0.2854\n",
    "\n",
    "# vertical coordinate with p in hPa\n",
    "log_pressure = lambda p: -H * np.log(p / ps)\n",
    "\n",
    "# potential temperature\n",
    "potential_temperature = lambda t, p: t * np.exp(np.log(ps/p) * kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50a6f0-5609-42f6-80d7-81890978b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.guvectorize(\n",
    "    \"(float64[:], float64[:], float64[:], float64[:])\",\n",
    "    \"(n), (n), (m) -> (m)\",\n",
    "    nopython=True,\n",
    ")\n",
    "def vectorized_interp(data,x,xi,out):\n",
    "    '''\n",
    "        Vectorized 1-D interpolation\n",
    "        \n",
    "        - much faster than looping or np.vectorize\n",
    "        - does not work with scipy's cubic spline interpolatin in nopython mode:\n",
    "          out[:] = interpolate.interp1d(x,data,kind='cubic',fill_value='extrapolate')(xi)\n",
    "    '''\n",
    "    out[:] = np.interp(xi,x,data)\n",
    "    \n",
    "    \n",
    "\n",
    "def to_regular_grid(da,z,dz,zmax,dim='isobaricInhPa'):\n",
    "    '''\n",
    "    '''\n",
    "    zi = xr.DataArray(np.arange(0,zmax+dz,dz),dims=('height',))\n",
    "    \n",
    "    regular = xr.apply_ufunc(vectorized_interp,\n",
    "                             *(da,z,zi),\n",
    "                             input_core_dims=[[dim],[dim],['height']],\n",
    "                             output_core_dims=[['height']],\n",
    "                             dask='parallelized',\n",
    "                             output_dtypes=[da.dtype]\n",
    "                            )\n",
    "    regular['height'] = zi\n",
    "    \n",
    "    return regular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ab997-ea3b-44ea-bba2-7afbcc689d55",
   "metadata": {},
   "source": [
    "## Power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6920be-3722-4981-9a5a-0c3c89da13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regridding(da,dz,zmax,pressure=None):\n",
    "    '''\n",
    "    '''\n",
    "    dims = list(da.dims)\n",
    "    if 'pressure' in dims:\n",
    "        dim = 'pressure'\n",
    "    elif 'level' in dims:\n",
    "        dim = 'level'\n",
    "    elif 'isobaricInhPa' in dims:\n",
    "        dim = 'isobaricInhPa'\n",
    "    elif 'hybrid' in dims:\n",
    "        dim = 'hybrid'\n",
    "    else:\n",
    "        raise KeyError('Vertical dimension not recognized')\n",
    "        \n",
    "    if pressure is None:\n",
    "        pressure = da[dim]\n",
    "    \n",
    "    theta = potential_temperature(da,pressure)\n",
    "    \n",
    "    z = log_pressure(pressure)\n",
    "    \n",
    "    regridded = to_regular_grid(theta,z,dz,zmax,dim=dim)\n",
    "    \n",
    "    return regridded\n",
    "\n",
    "\n",
    "\n",
    "def normalization(pert,full):\n",
    "    '''\n",
    "    '''\n",
    "    dims = list(pert.dims)\n",
    "    if 'longitude' in dims:\n",
    "        lon_name = 'longitude'\n",
    "        lat_name = 'latitude'\n",
    "        cos_phi= np.cos(np.radians(pert['latitude']))\n",
    "    elif 'lon' in dims:\n",
    "        lon_name = 'lon'\n",
    "        lat_name = 'lat'\n",
    "        cos_phi= np.cos(np.radians(pert['lat']))\n",
    "    else:\n",
    "        raise KeyError('Zonal dimension not recognized')\n",
    "    \n",
    "    mean = full.mean(lon_name).compute()\n",
    "    mean = mean.interp(**{lat_name:pert[lat_name]})\n",
    "    \n",
    "    \n",
    "    normalized = pert / mean\n",
    "    normalized = normalized * np.exp(-pert['height']/(2*H))\n",
    "    \n",
    "    norm = (normalized*np.sqrt(cos_phi)).std().compute() / cos_phi.mean()\n",
    "    normalized = normalized / norm\n",
    "    \n",
    "    return normalized, norm\n",
    "\n",
    "\n",
    "def tapering(da,height,dz):\n",
    "    '''\n",
    "    '''\n",
    "    alpha = 2 * int(height/dz) / len(da['height'])\n",
    "    window = xr.DataArray(tukey(len(da['height']),alpha=alpha),coords=dict(height=da['height']))\n",
    "    \n",
    "    tapered = da * window\n",
    "    return tapered\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def transformation(da,dz,dj=1/6):\n",
    "    '''\n",
    "    '''\n",
    "    da_ft = fft(da,'height',da['height'])\n",
    "    wavelet, wavelength, coi = wavelet_wrapper(len(da['height']),dz,dj=dj)\n",
    "    \n",
    "    transform = da_ft * wavelet\n",
    "    transform = ifft(transform,'height',da['height'])\n",
    "    \n",
    "    transform = transform.assign_coords(dict(scale=wavelength)).rename(scale='wavelength')\n",
    "    coi = coi.assign_coords(dict(scale=wavelength)).rename(scale='wavelength')\n",
    "    \n",
    "    return transform, coi\n",
    "    \n",
    "    \n",
    "def mean_power(da,taper,dz):\n",
    "    '''\n",
    "    '''\n",
    "    dims = list(da.dims)\n",
    "    dims.remove('wavelength')\n",
    "    dims.remove('height')\n",
    "    \n",
    "    Y = np.abs(da) ** 2\n",
    "    Y = Y.mean(dims)\n",
    "    \n",
    "    window = tapering(xr.ones_like(Y),taper,dz)\n",
    "    Y = Y / (window ** 2).mean()\n",
    "    \n",
    "    return Y.where(np.isfinite(Y.height),drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c67a9b-03ca-4f58-b69b-562c72da8922",
   "metadata": {},
   "source": [
    "## Parametric bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b041a-b3a4-4a71-8fb6-d53b613daa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.guvectorize(\n",
    "    \"(float64[:],float64[:],float64[:,:])\",\n",
    "    \"(n), (m) -> (m,n)\",\n",
    "    forceobj=True\n",
    ")\n",
    "def random_sample(a,nb,out):\n",
    "    '''\n",
    "        Draw len(nb) random samples from array a\n",
    "        'ziehen mit zuruecklegen'\n",
    "        \n",
    "        - nb is a dummy array to get dimension size\n",
    "    '''\n",
    "    lt = len(a)\n",
    "    variates = stats.uniform.rvs(0,lt,lt*len(nb))\n",
    "    variates = variates.astype(int).reshape(len(nb),lt)\n",
    "    out[:,:] = a[variates]\n",
    "    \n",
    "\n",
    "@numba.guvectorize(\n",
    "    \"(float64[:],float64[:],float64[:])\",\n",
    "    \"(n), (m) -> (m)\",\n",
    "    forceobj=True\n",
    ")    \n",
    "def ecdf(a,p,out):\n",
    "    '''\n",
    "        Emperical cummulative distribution function of array\n",
    "        at percentiles p\n",
    "    '''\n",
    "    sort = np.sort(a)\n",
    "    out[:] = sort[np.int64(p*len(a))]\n",
    "    \n",
    "    \n",
    "def t_statistic(x1,x2,dim):\n",
    "    '''\n",
    "        T-statistic for the difference of the mean for two samples of equal length\n",
    "    '''\n",
    "    diff = x1.mean(dim) - x2.mean(dim)\n",
    "    err = x1.var(dim) + x2.var(dim)\n",
    "    err = np.sqrt(err/len(x1[dim]))\n",
    "    return diff / err\n",
    "\n",
    "\n",
    "def parametric_bootstrap(sample1,sample2,nb=1000,confid=0.05):\n",
    "    '''\n",
    "        Test ensemble mean difference\n",
    "    '''\n",
    "    # Produce control samples that fullfill the Null hypothesis\n",
    "    c1 = sample1 - sample1.mean('number')\n",
    "    c2 = sample2 - sample2.mean('number')\n",
    "    \n",
    "    # Resample control\n",
    "    bootstrap = xr.DataArray(np.arange(nb),dims=('random'))\n",
    "    c1 = xr.apply_ufunc(random_sample,\n",
    "                         *(c1,bootstrap),\n",
    "                         input_core_dims=[['number'],['random']],\n",
    "                         output_core_dims=[['random','number']],\n",
    "                         dask='parallelized',\n",
    "                         output_dtypes=[[c1.dtype]])\n",
    "    c2 = xr.apply_ufunc(random_sample,\n",
    "                         *(c2,bootstrap),\n",
    "                         input_core_dims=[['number'],['random']],\n",
    "                         output_core_dims=[['random','number']],\n",
    "                         dask='parallized',\n",
    "                         output_dtypes=[[c1.dtype]])\n",
    "    \n",
    "    # t statistic for the resampled data\n",
    "    dist = t_statistic(c1,c2,'number')\n",
    "    \n",
    "    # emperical cumulative distribution function\n",
    "    p = xr.DataArray(np.linspace(0,0.999,1000),dims=('percentile'))\n",
    "    dist = xr.apply_ufunc(ecdf,\n",
    "                          *(dist,p),\n",
    "                          input_core_dims=[['random'],['percentile']],\n",
    "                          output_core_dims=[['percentile']],\n",
    "                          dask='parallelized',\n",
    "                          output_dtypes=[[dist.dtype]])\n",
    "    dist['percentile'] = p\n",
    "    \n",
    "    # check whether Null hypothesis can be rejected\n",
    "    t = t_statistic(sample1,sample2,'number')\n",
    "    sig = np.add(t < dist.sel(percentile=confid/2,method='nearest'), \n",
    "                 t > dist.sel(percentile=1-confid/2,method='nearest'))\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ec6f2-e44a-4767-b36f-cb895833e65b",
   "metadata": {},
   "source": [
    "## Computation - filtered model level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac837f-3e0b-4512-bba5-43547c19df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "realization = 8\n",
    "area = dict(latitude=slice(70,45))\n",
    "time_slice = ['2018-02-22',\n",
    "              '2018-03-22']\n",
    "\n",
    "\n",
    "model_levels = data_dir+'TCo639_nudged/20180208_91L/model_levels_40Nto80N_0.2x0.2/'\n",
    "\n",
    "pert = xr.open_dataset(model_levels+'T_pert_data/T_40Nto80N_%d_21_639_0.2x0.2_gg.grb'%realization,\n",
    "                       chunks=dict(step=1,latitude=2),engine='cfgrib')['t']\n",
    "pert = pert.drop(('step','time')).set_index(step='valid_time').rename(step='time')\n",
    "pert = pert.sel(time=slice(np.datetime64(time_slice[0]),np.datetime64(time_slice[1])),**area)\n",
    "\n",
    "lnsp = xr.open_dataset(model_levels+'lnsp/lnsp_%d.grb'%realization,chunks=dict(step=1,latitude=8))['lnsp']\n",
    "lnsp = lnsp.drop(('step','time')).set_index(step='valid_time').rename(step='time')\n",
    "lnsp = lnsp.sel(time=slice(np.datetime64(time_slice[0]),np.datetime64(time_slice[1])),**area)\n",
    "\n",
    "\n",
    "pressure_levels = data_dir+'TCo639_nudged/20180208_91L/pressure_levels_F64/'\n",
    "\n",
    "full = xr.open_dataset(pressure_levels+'t/t_%d.grb'%realization,\n",
    "                       chunks=dict(step=1,latitude=2),engine='cfgrib')['t']\n",
    "full = full.drop(('step','time')).set_index(step='valid_time').rename(step='time')\n",
    "full = full.sel(time=slice(np.datetime64(time_slice[0]),np.datetime64(time_slice[1])),**area)\n",
    "\n",
    "\n",
    "AandB = np.loadtxt('./AandB_91L.txt',skiprows=1)\n",
    "level = xr.DataArray(AandB[:,0],dims=('hybrid'),name='hybrid')\n",
    "A = xr.DataArray(AandB[:,1],dims=('hybrid'),coords=dict(hybrid=level),name='A')\n",
    "B = xr.DataArray(AandB[:,2],dims=('hybrid'),coords=dict(hybrid=level),name='B')\n",
    "\n",
    "pressure = (A + B * np.exp(lnsp)) / 100\n",
    "\n",
    "pressure = pressure.reindex(hybrid=pressure.hybrid[:0:-1])\n",
    "pert = pert.reindex(hybrid=pert.hybrid[:0:-1])\n",
    "\n",
    "pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66241d-a7de-458c-a863-d6ed6853546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = 100\n",
    "zmax = 64000\n",
    "taper = zmax/2\n",
    "\n",
    "full_regrid = regridding(full,dz,zmax)\n",
    "pert_regrid = regridding(pert,dz,zmax,pressure)\n",
    "normalized, norm = normalization(pert_regrid,full_regrid)\n",
    "tapered = tapering(normalized,taper,dz)\n",
    "transformed, coi = transformation(tapered,dz)\n",
    "\n",
    "power = mean_power(transformed,taper,dz)\n",
    "power = power.compute()\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478cb3e-a1cc-42ce-92d8-c36772657ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'spectogram_'+str(realization)+'_'+time_slice[0]+'_'+time_slice[1]\n",
    "xr.Dataset(dict(power=power,norm=norm,coi=coi)).to_netcdf(work_dir+title+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233e06a-5296-42bd-8c2a-5f54285441b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e4f9eb-bb49-4379-a0c3-c156c3dd0280",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Ensemble-mean non-dimensional potential energy wavelet spectrum horizontally averaged between 45 and 70Â° N for the period 22 February to 22 March 2018 in the (a) TCo639L91 and (b) TCo639L198 nudged simulations and (c) the ensemble-mean difference TCo639L198 - TCo639L91. The hatched area indicates the theoretical cone of influence and stippling in the lower panel indicates where ensemble-mean energies are not significantly different estimated by a parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4dbfa-576a-40ec-88eb-273fb3f9ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_wavelet_spectra(L91,L198,H=7000):\n",
    "    '''\n",
    "    '''\n",
    "    lambdas = L91['wavelength'].values / 1000\n",
    "    zmax = L91['height'].max().values  / 1000\n",
    "    coi = L91['coi'].mean('number')    / 1000\n",
    "    coi['wavelength'] = coi['wavelength'] / 1000\n",
    "    \n",
    "    L91 = (L91['power'] * L91['norm']).sel(wavelength=slice(0,2*H))\n",
    "    L91['wavelength'] = L91['wavelength'] / 1000\n",
    "    L91['height'] = L91['height'] / 1000\n",
    "    L198 = (L198['power'] * L198['norm']).sel(wavelength=slice(0,2*H))\n",
    "    L198['wavelength'] = L198['wavelength'] / 1000\n",
    "    L198['height'] = L198['height'] / 1000\n",
    "    \n",
    "    difference = L198.mean('number') - L91.mean('number')\n",
    "    \n",
    "    sig = parametric_bootstrap(L198,L91,nb=4000)\n",
    "    \n",
    "    # plotting\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3,sharex='all',figsize=(6,9))\n",
    "    \n",
    "    # first subplot\n",
    "    \n",
    "    C1 = L91.mean('number').plot.pcolormesh(ax=axes[0],\n",
    "                           y='height',\n",
    "                           levels=np.linspace(0,0.04,21),\n",
    "                           cmap=cmocean.cm.matter,\n",
    "                           extend='max',\n",
    "                           add_colorbar=False)\n",
    "\n",
    "    axes[0].fill_between(lambdas,\n",
    "                np.zeros(len(lambdas)),\n",
    "                coi.sel(wavelength=lambdas).values,\n",
    "                color='k', alpha=0.3, hatch='x')\n",
    "\n",
    "    axes[0].fill_between(lambdas,\n",
    "                zmax - coi.sel(wavelength=lambdas).values,\n",
    "                zmax * np.ones(len(lambdas)),\n",
    "                color='k', alpha=0.3, hatch='x')\n",
    "    \n",
    "    axes[0].set_ylabel('height [km]')\n",
    "    axes[0].set_xlabel(None)\n",
    "    \n",
    "    ax = axes[0].twinx()\n",
    "    ylim = axes[0].get_ylim()\n",
    "    ax.set_ylim(1013.25*np.exp(-np.array(ylim)*1000/H))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('pressure [hPa]')\n",
    "    \n",
    "    ax = axes[0].twinx()\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('energy L91',labelpad=80,size=18,weight='bold')\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    \n",
    "    \n",
    "    # second subplot\n",
    "    \n",
    "    L198.mean('number').plot.pcolormesh(ax=axes[1],\n",
    "                           y='height',\n",
    "                           levels=np.linspace(0,0.04,21),\n",
    "                           cmap=cmocean.cm.matter,\n",
    "                           extend='max',\n",
    "                           add_colorbar=False)\n",
    "\n",
    "    axes[1].fill_between(lambdas,\n",
    "                np.zeros(len(lambdas)),\n",
    "                coi.sel(wavelength=lambdas).values,\n",
    "                color='k', alpha=0.3, hatch='x')\n",
    "\n",
    "    axes[1].fill_between(lambdas,\n",
    "                zmax - coi.sel(wavelength=lambdas).values,\n",
    "                zmax * np.ones(len(lambdas)),\n",
    "                color='k', alpha=0.3, hatch='x')\n",
    "    \n",
    "    axes[1].set_ylabel('height [km]')\n",
    "    axes[1].set_xlabel(None)\n",
    "    \n",
    "    ax = axes[1].twinx()\n",
    "    ylim = axes[1].get_ylim()\n",
    "    ax.set_ylim(1013.25*np.exp(-np.array(ylim)*1000/H))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('pressure [hPa]')\n",
    "    \n",
    "    ax = axes[1].twinx()\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('energy L198',labelpad=80,size=18,weight='bold')\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    \n",
    "    \n",
    "    # third subplot\n",
    "    \n",
    "    C2 = difference.plot.pcolormesh(ax=axes[2],\n",
    "                               y='height',\n",
    "                               levels=np.linspace(-0.02,0.02,25),\n",
    "                               cmap=cmocean.cm.balance,\n",
    "                               extend='both',\n",
    "                               add_colorbar=False)\n",
    "    \n",
    "    sig.astype(np.double).plot.contourf(ax=axes[2],y='height',levels=[0,0.5,1],hatches=['.',''],\n",
    "                                        alpha=0,add_colorbar=False)\n",
    "    \n",
    "\n",
    "    axes[2].fill_between(lambdas,\n",
    "                    np.zeros(len(lambdas)),\n",
    "                    coi.sel(wavelength=lambdas).values,\n",
    "                    color='k', alpha=0.3, hatch='x')\n",
    "\n",
    "    axes[2].fill_between(lambdas,\n",
    "                    zmax - coi.sel(wavelength=lambdas).values,\n",
    "                    zmax * np.ones(len(lambdas)),\n",
    "                    color='k', alpha=0.3, hatch='x')\n",
    "    \n",
    "    axes[2].set_ylabel('height [km]')\n",
    "    axes[2].set_xlabel('wavelength [km]')\n",
    "    \n",
    "    ax = axes[2].twinx()\n",
    "    ylim = axes[2].get_ylim()\n",
    "    ax.set_ylim(1013.25*np.exp(-np.array(ylim)*1000/H))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('pressure [hPa]')\n",
    "    \n",
    "    ax = axes[2].twinx()\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('difference L198-L91',labelpad=80,size=18,weight='bold')\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    \n",
    "    # shared\n",
    "    trans = mtransforms.ScaledTranslation(-45/72, -20/72, fig.dpi_scale_trans)\n",
    "    \n",
    "    axes[0].text(-0.06,1.1,'a)',transform=axes[0].transAxes+trans,fontsize='large',va='bottom',fontfamily='serif')\n",
    "    axes[1].text(-0.06,1.1,'b)',transform=axes[1].transAxes+trans,fontsize='large',va='bottom',fontfamily='serif')\n",
    "    axes[2].text(-0.06,1.1,'c)',transform=axes[2].transAxes+trans,fontsize='large',va='bottom',fontfamily='serif')\n",
    "    \n",
    "    fig.subplots_adjust(0,0,1,0.95,0,0)\n",
    "    \n",
    "    cbar = plt.colorbar(C1,ax=axes[0:2],orientation='vertical',fraction=0.1,aspect=20,shrink=0.95,pad=0.15)\n",
    "    \n",
    "    cbar = plt.colorbar(C2,ax=axes[2],orientation='vertical',fraction=0.1,aspect=10,shrink=0.95,pad=0.15)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "time_slice = ['2018-02-22',\n",
    "              '2018-03-22']\n",
    "suffix = '_'+time_slice[0]+'_'+time_slice[1]+'.nc'\n",
    "\n",
    "experiment = 'TCo639_nudged_198L'\n",
    "files_single = !ls {'./vertical_wavelet_power_spectra/'+experiment+'/spectogram_?'+suffix}\n",
    "files_double = !ls {'./vertical_wavelet_power_spectra/'+experiment+'/spectogram_??'+suffix}\n",
    "L198 = xr.open_mfdataset(files_single+files_double,combine='nested',concat_dim='number').load()\n",
    "\n",
    "experiment = 'TCo639_nudged_91L'\n",
    "files_single = !ls {'./vertical_wavelet_power_spectra/'+experiment+'/spectogram_?'+suffix}\n",
    "files_double = !ls {'./vertical_wavelet_power_spectra/'+experiment+'/spectogram_??'+suffix}\n",
    "L91 = xr.open_mfdataset(files_single+files_double,combine='nested',concat_dim='number').load()\n",
    "\n",
    "compare_wavelet_spectra(L91,L198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebdb888-a0a1-47e1-aea9-90f1f734a890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IFS_GW_SSW]",
   "language": "python",
   "name": "conda-env-IFS_GW_SSW-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
